{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import os\n",
    "from scipy import stats\n",
    "import docx\n",
    "from sentence_transformers import SentenceTransformer, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"align_overview_sum - align_overview_sum.csv\")\n",
    "data = meta.loc[(meta['Arousal_binary'] != -1) & (meta['Valence_binary'] != -1) & (meta['check date'] != 0)].reset_index(drop=True)\n",
    "data['ID'] = data['audio'].str[:5]\n",
    "fspeak = [\"P_001\",\"P_002\",\"P_003\",\"P_004\",\"P_005\",\"P_006\",\"P_007\",\"P_008\",\"P_009\",\"P_010\",\"P_011\",\"Z_012\",\"P_013\"]\n",
    "mspeak = [\"Z_001\",\"Z_002\",\"Z_003\",\"Z_004\",\"Z_005\",\"Z_006\",\"Z_007\",\"Z_008\",\"Z_009\",\"Z_010\",\"Z_011\",\"P_012\",\"Z_013\"]\n",
    "data = data.loc[(data[\"female speak\"] == \"yes\") & (data[\"male speak\"] == \"yes\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transcript paths and assign gender\n",
    "\n",
    "meta_data = data.copy()\n",
    "fspeak = [\"P_001\",\"P_002\",\"P_003\",\"P_004\",\"P_005\",\"P_006\",\"P_007\",\"P_008\",\"P_009\",\"P_010\",\"P_011\",\"Z_012\",\"P_013\"]\n",
    "mspeak = [\"Z_001\",\"Z_002\",\"Z_003\",\"Z_004\",\"Z_005\",\"Z_006\",\"Z_007\",\"Z_008\",\"Z_009\",\"Z_010\",\"Z_011\",\"P_012\",\"Z_013\"]\n",
    "meta_data.loc[meta_data['ID'].isin(fspeak), 'Gender'] = \"f\"\n",
    "meta_data.loc[meta_data['ID'].isin(mspeak), 'Gender'] = \"m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>contain speech</th>\n",
       "      <th>female speak</th>\n",
       "      <th>male speak</th>\n",
       "      <th>female transcript</th>\n",
       "      <th>male transcript</th>\n",
       "      <th>annotate</th>\n",
       "      <th>useful annotates</th>\n",
       "      <th>female chunk number</th>\n",
       "      <th>aligned female chunk number</th>\n",
       "      <th>...</th>\n",
       "      <th>Arousal_binary</th>\n",
       "      <th>Valence_binary</th>\n",
       "      <th>check annotation</th>\n",
       "      <th>check female transcript</th>\n",
       "      <th>check male transcript</th>\n",
       "      <th>check date</th>\n",
       "      <th>romantic interaction</th>\n",
       "      <th>romantic interaction &amp; both speak</th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_001\\Day_2\\Hour_16\\07-16-2019 16_44_00</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>P_001</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_001\\Day_2\\Hour_18\\07-16-2019 18_24_27</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>P_001</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_001\\Day_2\\Hour_9\\07-16-2019 09_00_26</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>P_001</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_001\\Day_3\\Hour_16\\07-17-2019 16_06_50</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>P_001</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_001\\Day_3\\Hour_17\\07-17-2019 17_02_08</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>P_001</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Z_012\\Day_1\\Hour_9\\08-09-2021 09_21_24</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Z_012</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Z_013\\Day_4\\Hour_21\\10-21-2021 21_31_33</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Z_013</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Z_013\\Day_3\\Hour_21\\10-20-2021 21_44_00</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Z_013</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Z_013\\Day_2\\Hour_21\\10-19-2021 21_12_32</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Z_013</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Z_013\\Day_0\\Hour_20\\10-24-2021 20_11_31</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Z_013</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       audio contain speech female speak  \\\n",
       "0    P_001\\Day_2\\Hour_16\\07-16-2019 16_44_00            yes          yes   \n",
       "1    P_001\\Day_2\\Hour_18\\07-16-2019 18_24_27            yes          yes   \n",
       "2     P_001\\Day_2\\Hour_9\\07-16-2019 09_00_26            yes          yes   \n",
       "3    P_001\\Day_3\\Hour_16\\07-17-2019 16_06_50            yes          yes   \n",
       "4    P_001\\Day_3\\Hour_17\\07-17-2019 17_02_08            yes          yes   \n",
       "..                                       ...            ...          ...   \n",
       "375   Z_012\\Day_1\\Hour_9\\08-09-2021 09_21_24            yes          yes   \n",
       "376  Z_013\\Day_4\\Hour_21\\10-21-2021 21_31_33            yes          yes   \n",
       "377  Z_013\\Day_3\\Hour_21\\10-20-2021 21_44_00            yes          yes   \n",
       "378  Z_013\\Day_2\\Hour_21\\10-19-2021 21_12_32            yes          yes   \n",
       "379  Z_013\\Day_0\\Hour_20\\10-24-2021 20_11_31            yes          yes   \n",
       "\n",
       "    male speak  female transcript  male transcript  annotate  \\\n",
       "0          yes                  1                1         1   \n",
       "1          yes                  1                1         1   \n",
       "2          yes                  1                1         0   \n",
       "3          yes                  1                1         1   \n",
       "4          yes                  1                1         1   \n",
       "..         ...                ...              ...       ...   \n",
       "375        yes                  1                1         1   \n",
       "376        yes                  1                1         1   \n",
       "377        yes                  1                1         1   \n",
       "378        yes                  1                1         1   \n",
       "379        yes                  1                1         1   \n",
       "\n",
       "     useful annotates  female chunk number  aligned female chunk number  ...  \\\n",
       "0                   5                    2                            2  ...   \n",
       "1                  29                   18                           12  ...   \n",
       "2                  -1                    7                           -1  ...   \n",
       "3                  13                   20                            9  ...   \n",
       "4                  46                   18                           15  ...   \n",
       "..                ...                  ...                          ...  ...   \n",
       "375                46                   18                           18  ...   \n",
       "376                 1                   12                            1  ...   \n",
       "377                 4                    5                            2  ...   \n",
       "378                28                   19                           18  ...   \n",
       "379                 9                    8                            7  ...   \n",
       "\n",
       "     Arousal_binary  Valence_binary  check annotation  \\\n",
       "0                 1               1                 1   \n",
       "1                 1               1                 1   \n",
       "2                 1               1                 0   \n",
       "3                 1               1                 1   \n",
       "4                 1               1                 1   \n",
       "..              ...             ...               ...   \n",
       "375               1               1                 1   \n",
       "376               0               1                 1   \n",
       "377               0               1                 1   \n",
       "378               1               1                 1   \n",
       "379               0               1                 1   \n",
       "\n",
       "     check female transcript  check male transcript  check date  \\\n",
       "0                          1                      1           1   \n",
       "1                          1                      1           1   \n",
       "2                          1                      1           1   \n",
       "3                          1                      1           1   \n",
       "4                          1                      1           1   \n",
       "..                       ...                    ...         ...   \n",
       "375                        1                      1           1   \n",
       "376                        1                      1           1   \n",
       "377                        1                      1           1   \n",
       "378                        1                      1           1   \n",
       "379                        1                      1           1   \n",
       "\n",
       "     romantic interaction  romantic interaction & both speak     ID  Gender  \n",
       "0                       1                                  1  P_001       f  \n",
       "1                       1                                  1  P_001       f  \n",
       "2                       1                                  1  P_001       f  \n",
       "3                       1                                  1  P_001       f  \n",
       "4                       1                                  1  P_001       f  \n",
       "..                    ...                                ...    ...     ...  \n",
       "375                     0                                 -1  Z_012       f  \n",
       "376                     1                                  1  Z_013       m  \n",
       "377                     1                                  1  Z_013       m  \n",
       "378                     1                                  1  Z_013       m  \n",
       "379                     1                                  1  Z_013       m  \n",
       "\n",
       "[380 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits =splits = meta_data['audio'].str.split(\"\\\\\").str.join(\"_\").str.split(\"_\")\n",
    "name = splits.str[0:2].str.join(\"\")\n",
    "day = splits.str[2:5].str.join(\"_\")\n",
    "hour = splits.str[5].str.zfill(2)\n",
    "time = splits.str[2:6].str.join(\"_\")\n",
    "date = splits.str[6:].str.join(\"_\")\n",
    "\n",
    "meta_data['transcript_path'] = \"transcript_\" + name + \"_\" + time + \"-\" + date + \"_\" + meta_data['Gender']\n",
    "# meta_data['transcript_path'] = \"transcript_\" + name + \"_\" + day + \"_\" + hour + \"-\" + date + \"_\" + meta_data['Gender']\n",
    "\n",
    "# Getting full path \n",
    "meta_data['transcript_full_path'] = \"Z:\\\\DyMand Data\\\\Transcripts\\\\\" + meta_data['transcript_path'].str[11:15] + \"\\\\\" + meta_data['transcript_path'] + \".docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path = meta_data['transcript_full_path'].tolist()\n",
    "gender_type = meta_data['Gender'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToText(file):\n",
    "    # Load file\n",
    "    load_doc = docx.Document(file)\n",
    "    \n",
    "    text = []\n",
    "    # Iterate over paragraphs\n",
    "    for para in load_doc.paragraphs:\n",
    "        \n",
    "        # Preprocessing\n",
    "        text_filtered = para.text.replace(\"//\",\"\").replace(\"XX\",\"\").replace(\"XY\",\"\").replace(\"\\n\\n\",\"\")\n",
    "        \n",
    "        if text_filtered and text_filtered.strip():\n",
    "            text.append(text_filtered)\n",
    "    \n",
    "    \n",
    "    trans = \",\".join(text)\n",
    "    \n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file: Z:\\DyMand Data\\Transcripts\\Z007\\transcript_Z007_Day_5_Hour_10-02-14-2020 10_44_24_m.docx\n"
     ]
    }
   ],
   "source": [
    "# Create csv of transcripts\n",
    "transcripts = []\n",
    "skips = []\n",
    "for path, gender in zip(transcript_path, gender_type):\n",
    "    \n",
    "    try:\n",
    "        trans_file = convertToText(path)\n",
    "    except:\n",
    "        print(\"Skipping file:\", path)\n",
    "        skips.append(path)\n",
    "        continue\n",
    "        \n",
    "#     file_process = path.split(\"\\\\\")[-1][11:29]\n",
    "#     filename = file_process[0] + \"_\" + file_process[1:]\n",
    "\n",
    "\n",
    "    file_process = path.split(\"\\\\\")[-1].split(\"_\")[1:6]\n",
    "    hour = file_process[4].split(\"-\")[0]\n",
    "    name = file_process[0][0] + \"_\" + file_process[0][1:] +\"_\" + \"_\".join(file_process[1:4])\n",
    "    filename = name + \"_\" + hour\n",
    "    file = [filename, gender, trans_file]\n",
    "    transcripts.append(file)\n",
    "    \n",
    "transcripts_df = pd.DataFrame(transcripts, columns = ['Name', 'Gender','Transcript'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_df.to_csv(\"transcript/transcript.csv\", index=False)\n",
    "\n",
    "# Remember to run DyMand Linguistic features before evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_001_Day_2_Hour_16</td>\n",
       "      <td>f</td>\n",
       "      <td>Du musst dann da noch vom Raf.. Raffi… Schak....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_001_Day_2_Hour_18</td>\n",
       "      <td>f</td>\n",
       "      <td>Danke. Ist jetzt bei dir noch immer nichts gek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_001_Day_3_Hour_16</td>\n",
       "      <td>f</td>\n",
       "      <td>Man könnte ja, aber du. Nicht, nein. Die komme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_001_Day_3_Hour_17</td>\n",
       "      <td>f</td>\n",
       "      <td>Das ist höher oben. Mhm  ist ja hier, geknecht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_001_Day_3_Hour_19</td>\n",
       "      <td>f</td>\n",
       "      <td>Und für alle diese Jahre sei die Versicherung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Z_012_Day_1_Hour_9</td>\n",
       "      <td>f</td>\n",
       "      <td>Ja. Das ist schon doof, mit dieser Frisur hier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Z_013_Day_4_Hour_21</td>\n",
       "      <td>m</td>\n",
       "      <td>Du kannst   . Ich muss schauen wegen meinter M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Z_013_Day_3_Hour_21</td>\n",
       "      <td>m</td>\n",
       "      <td>Ich habe deine Socken alle gewendet um einen d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Z_013_Day_2_Hour_21</td>\n",
       "      <td>m</td>\n",
       "      <td>schon gemerkt.  Im  Örlikon getroffen. Weil S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Z_013_Day_0_Hour_20</td>\n",
       "      <td>m</td>\n",
       "      <td>magst du auch ?  ,  Stell dir vor.   Wills...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Gender  \\\n",
       "0    P_001_Day_2_Hour_16      f   \n",
       "1    P_001_Day_2_Hour_18      f   \n",
       "2    P_001_Day_3_Hour_16      f   \n",
       "3    P_001_Day_3_Hour_17      f   \n",
       "4    P_001_Day_3_Hour_19      f   \n",
       "..                   ...    ...   \n",
       "373   Z_012_Day_1_Hour_9      f   \n",
       "374  Z_013_Day_4_Hour_21      m   \n",
       "375  Z_013_Day_3_Hour_21      m   \n",
       "376  Z_013_Day_2_Hour_21      m   \n",
       "377  Z_013_Day_0_Hour_20      m   \n",
       "\n",
       "                                            Transcript  \n",
       "0     Du musst dann da noch vom Raf.. Raffi… Schak....  \n",
       "1    Danke. Ist jetzt bei dir noch immer nichts gek...  \n",
       "2    Man könnte ja, aber du. Nicht, nein. Die komme...  \n",
       "3    Das ist höher oben. Mhm  ist ja hier, geknecht...  \n",
       "4    Und für alle diese Jahre sei die Versicherung ...  \n",
       "..                                                 ...  \n",
       "373  Ja. Das ist schon doof, mit dieser Frisur hier...  \n",
       "374  Du kannst   . Ich muss schauen wegen meinter M...  \n",
       "375  Ich habe deine Socken alle gewendet um einen d...  \n",
       "376   schon gemerkt.  Im  Örlikon getroffen. Weil S...  \n",
       "377      magst du auch ?  ,  Stell dir vor.   Wills...  \n",
       "\n",
       "[378 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for correct speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying filtering to remove incorrect speakers\n",
    "\n",
    "fspeak = [\"P001\",\"P002\",\"P003\",\"P004\",\"P005\",\"P006\",\"P007\",\"P008\",\"P009\",\"P010\",\"P011\",\"Z012\",\"P013\"]\n",
    "mspeak = [\"Z001\",\"Z002\",\"Z003\",\"Z004\",\"Z005\",\"Z006\",\"Z007\",\"Z008\",\"Z009\",\"Z010\",\"Z011\",\"P012\",\"Z013\"]\n",
    "transcripts_df['ID'] = transcripts_df['Name'].str.split(\"_\").str[:2].str.join(\"\")\n",
    "transcriptions_df_filtered = transcripts_df.loc[(transcripts_df['ID'].isin(fspeak)) & (transcripts_df[\"Gender\"] == \"f\") | (transcripts_df['ID'].isin(mspeak)) & (transcripts_df[\"Gender\"] == \"m\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions_df_filtered.reset_index(drop=True,inplace=True)\n",
    "transcriptions_df_filtered\n",
    "transcriptions_df_filtered.to_csv(\"transcript/transcript.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding skipped transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Z:\\DyMand Data\\Transcripts\\P001\\transcript_P00...\n",
       "1    Z:\\DyMand Data\\Transcripts\\P004\\transcript_P00...\n",
       "2    Z:\\DyMand Data\\Transcripts\\P004\\transcript_P00...\n",
       "3    Z:\\DyMand Data\\Transcripts\\P005\\transcript_P00...\n",
       "4    Z:\\DyMand Data\\Transcripts\\P009\\transcript_P00...\n",
       "5    Z:\\DyMand Data\\Transcripts\\P009\\transcript_P00...\n",
       "6    Z:\\DyMand Data\\Transcripts\\Z004\\transcript_Z00...\n",
       "7    Z:\\DyMand Data\\Transcripts\\Z004\\transcript_Z00...\n",
       "8    Z:\\DyMand Data\\Transcripts\\Z006\\transcript_Z00...\n",
       "9    Z:\\DyMand Data\\Transcripts\\Z007\\transcript_Z00...\n",
       "Name: transcript, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the skipped transcripts\n",
    "trans_skipped = pd.DataFrame(skips, columns = ['transcript'])\n",
    "trans_skipped['gender'] = trans_skipped['transcript'].str[-6:-5]\n",
    "trans_skipped['ID'] = trans_skipped['transcript'].str.split(\"\\\\\").str[3]\n",
    "fspeak = [\"P001\",\"P002\",\"P003\",\"P004\",\"P005\",\"P006\",\"P007\",\"P008\",\"P009\",\"P010\",\"P011\",\"Z012\",\"P013\"]\n",
    "mspeak = [\"Z001\",\"Z002\",\"Z003\",\"Z004\",\"Z005\",\"Z006\",\"Z007\",\"Z008\",\"Z009\",\"Z010\",\"Z011\",\"P012\",\"Z013\"]\n",
    "transcriptions_skipped_gender_filtered = trans_skipped.loc[(trans_skipped['ID'].isin(fspeak)) & (trans_skipped[\"gender\"] == \"f\") | (trans_skipped['ID'].isin(mspeak)) & (trans_skipped[\"gender\"] == \"m\")]\n",
    "transcriptions_skipped_gender_filtered.reset_index(drop=True, inplace=True)\n",
    "transcriptions_skipped_gender_filtered['transcript']\n",
    "# transcriptions_skipped_gender_filtered.to_csv(\"transcriptions_skipped_priority.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
